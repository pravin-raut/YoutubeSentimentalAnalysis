{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import google.auth\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build"
      ],
      "metadata": {
        "id": "kNXTI7y4l98E"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Youtube_Kafka/Kafka_Class.ipynb /content/"
      ],
      "metadata": {
        "id": "TZbqJPPOnRfW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run  /content/Kafka_Class.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kok3V2x7pT4c",
        "outputId": "a7746bab-c27e-4b32-ebb4-53ff848b5691"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the configuration properties\n",
        "topic_name = \"SentimentalAnalysis\"\n",
        "bootstrap_servers_list = [\"34.16.136.159:9092\",\"34.16.136.159:9093\",\"34.16.136.159:9094\"]"
      ],
      "metadata": {
        "id": "lkbzrzoJqiWk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kc=KafkaConnect(bootstrap_servers_list,topic_name)"
      ],
      "metadata": {
        "id": "oC02Gk3g3zsq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kc.get_topic_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DChEQy8fsJQH",
        "outputId": "36c39288-b280-4085-f7f3-aa04d4c750bc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Kafka topics:\n",
            "SentimentalAnalysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kc.create_topic(2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUcff8jGsAM4",
        "outputId": "e69e0276-0e9f-43da-fa4e-e6651f03eaea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kafka topic SentimentalAnalysis successfully created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kc.deleteTopic('SentimentalAnalysis')"
      ],
      "metadata": {
        "id": "S_Qj8l4vAH7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c80310f-0536-4f35-ad47-edaa0e028a90"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kafka topic SentimentalAnalysis successfully deleted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the file for reading and load the data from it\n",
        "with open(\"/content/drive/MyDrive/Configuration/Config.json\", \"r\") as infile:\n",
        "  data = json.load(infile)\n",
        "# Set up API key\n",
        "  api_key=data[\"Youtube\"][\"api_key\"]\n"
      ],
      "metadata": {
        "id": "PH_9iCIXmF8x"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "V_xkIIxyl3su"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dateutil import parser\n",
        "from datetime import datetime\n",
        "\n",
        "def GetNewCommentsFromYoutube(video_id, comments_dict, last_comment_time_path=None):\n",
        "    # Read last comment timestamp from file\n",
        "    last_comment_time = None\n",
        "    if last_comment_time_path is not None and os.path.isfile(last_comment_time_path):\n",
        "        with open(last_comment_time_path, 'r') as f:\n",
        "            last_comment_time = parser.parse(f.read().strip())\n",
        "\n",
        "    # Set up YouTube API client\n",
        "    youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "    # Retrieve comments for the video\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        response = youtube.commentThreads().list(\n",
        "            part=\"snippet,replies\",\n",
        "            videoId=video_id,\n",
        "            textFormat=\"plainText\",\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        for item in response[\"items\"]:\n",
        "            comment_time = parser.parse(item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
        "            if last_comment_time is not None and comment_time <= last_comment_time:\n",
        "                # Stop processing comments if we reach the last processed comment\n",
        "                break\n",
        "            else:\n",
        "                comment_id = item[\"snippet\"][\"topLevelComment\"][\"id\"]\n",
        "                comment = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
        "                comment_likes = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"]\n",
        "                comments_dict[comment_id] = {'comment': comment, 'comment_likes': comment_likes}\n",
        "\n",
        "                if \"replies\" in item:\n",
        "                    for reply_item in item[\"replies\"][\"comments\"]:\n",
        "                        reply_time = parser.parse(reply_item[\"snippet\"][\"publishedAt\"])\n",
        "                        if last_comment_time is not None and reply_time <= last_comment_time:\n",
        "                            # Stop processing comments if we reach the last processed comment\n",
        "                            break\n",
        "                        else:\n",
        "                            reply_id = reply_item[\"id\"]\n",
        "                            reply = reply_item[\"snippet\"][\"textDisplay\"]\n",
        "                            reply_likes = reply_item[\"snippet\"][\"likeCount\"]\n",
        "                            comments_dict[reply_id] = {'reply': reply, 'reply_likes': reply_likes}\n",
        "\n",
        "        if \"nextPageToken\" in response:\n",
        "            next_page_token = response[\"nextPageToken\"]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Write last comment timestamp to file\n",
        "    if last_comment_time_path is not None:\n",
        "        last_comment_time = parser.parse(response[\"items\"][0][\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"])\n",
        "        with open(last_comment_time_path, 'w') as f:\n",
        "            f.write(last_comment_time.isoformat())\n",
        "\n",
        "    return comments_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "comments_dict = {}\n",
        "video_id = \"I1jUQK-yEBo\"\n",
        "last_comment_time_path = \"last_comment_id.txt\"\n",
        "\n"
      ],
      "metadata": {
        "id": "qSY3xW9pmkvV"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  time.sleep(2)\n",
        "  comments_dict = {}\n",
        "  GetNewCommentsFromYoutube(video_id, comments_dict, last_comment_time_path)\n",
        "  for key,message in comments_dict.items():\n",
        "      message_str = json.dumps(message)\n",
        "      kc.produceMessage(key.encode(),message_str.encode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "sVx9a4Q-HGq1",
        "outputId": "c3e669f9-2baf-470b-b18b-45cd1e62212b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message published successfully to Kafka!\n",
            "Message published successfully to Kafka!\n",
            "Message published successfully to Kafka!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-94773e359192>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mcomments_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mGetNewCommentsFromYoutube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_comment_time_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomments_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8Zye1jsHGg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}