{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0fff43e-eaa0-468c-b26a-53ed167f15e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the configuration properties\n",
    "topic_name = \"SentimentalAnalysis\"\n",
    "bootstrap_servers_list = \"34.125.251.10:9092,34.125.251.10:9093,34.125.251.10:9094\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be9db8cf-3878-470a-aea7-084f85719549",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "starting_offset = \"earliest\"\n",
    "consumer_group=\"Group1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cd3f620-0960-47ac-8868-cda98c41dc3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "# Define the schema for the data in the Kafka topic\n",
    "schema = StructType([\n",
    "    StructField(\"key\", StringType(), True),\n",
    "    StructField(\"value\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9fe00f4-89db-4945-a40a-ad6af2d6d29e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", bootstrap_servers_list) \\\n",
    "        .option(\"subscribe\", topic_name) \\\n",
    "        .option(\"startingOffsets\", starting_offset) \\\n",
    "        .option(\"group.id\", consumer_group) \\\n",
    "        .load() \\\n",
    "        .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29e16b70-e361-41ac-8806-91f39f34f5a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "schema = \"comment STRING, comment_likes INT\"\n",
    "parsed_df = df.select(\"key\",from_json(col(\"value\"), schema).alias(\"parsed_value\"))\n",
    "result_df = parsed_df.select(\"key\",\"parsed_value.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76120550-3682-4923-bad9-1b8f0b065fc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# Define a UDF (user-defined function) to apply sentiment analysis to a comment\n",
    "def get_sentiment(comment):\n",
    "    score = TextBlob(comment).sentiment.polarity\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcb30f19-f2bf-447a-b596-1679366fe55e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the UDF\n",
    "sentiment_udf = udf(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cea52856-0d82-456e-a332-d115ad99325f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a new column 'sentiment_score' to the DataFrame\n",
    "result_df_new = result_df.withColumn('Sentiment', sentiment_udf(col('comment')))\n",
    "result_df_new.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1174977531027491,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Youtube-Kafka-Consumer-Sentimental",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
